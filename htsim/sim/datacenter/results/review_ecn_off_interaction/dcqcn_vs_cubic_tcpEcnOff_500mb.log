topology file: htsim/sim/datacenter/topologies/leaf_spine_128_1to1.topo
traffic matrix file: htsim/sim/datacenter/connection_matrices/incast_2to1_size500MB.cm
queue size 100 packets
end_time 200000 us
random seed 13
DCQCN ratio 0.5
TCP Cubic initial cwnd 10 packets
TCP Cubic HyStart enabled
TCP Cubic fast convergence enabled
ECN enabled
TCP Cubic ECN response disabled
CSV output: htsim/sim/datacenter/results/review_ecn_off_interaction/dcqcn_vs_cubic_tcpEcnOff_500mb.csv
Logging to htsim/sim/datacenter/results/review_ecn_off_interaction/dcqcn_vs_cubic_tcpEcnOff_500mb.dat
RoceSinkLoggerSampling(p=0.00025 init 
Loading connection matrix from htsim/sim/datacenter/connection_matrices/incast_2to1_size500MB.cm
Nodes: 128 Connections: 2 Triggers: 0 Failures: 0
Using 128 nodes
Topology load done
Fat Tree topology (0) with 1us Src-ToR links, 1us ToR-Agg links, 0us ToR switch latency, 0us Agg switch latency for 4us diameter latency.
no_of_tor_uplinks: 128
No of nodes: 128
No of pods: 1
Hosts per pod: 128
Hosts per pod: 128
ToR switches per pod: 8
Agg switches per pod: 16
No of core switches: 0
FatTreeCfg constructor done.
Tier 0 QueueSize Down 150000 bytes
Tier 0 QueueSize Up 150000 bytes
Tier 1 QueueSize Down 150000 bytes
Tier 1 QueueSize Up 150000 bytes
Tier 2 QueueSize Down 150000 bytes
ECN thresholds: low=37500 bytes, high=145500 bytes
FatTreeTopologyCfg NCORE=0 NAGG=16 NTOR=8 NSRV=128 NPOD=1 tor_switches_per_pod=8 agg_switches_per_pod=16 tiers=2 host_per_pod=128 enabled_ecn=1 enable_ecn_on_tor_downlink=1 ecn_low=37500 ecn_high=145500 num_failed_links=0 failed_link_ratio=0.25 no_of_nodes=128 hop_latency=0 switch_latency=0 diameter_latency=4000000 diameter=4 tier=0 link_latency=1000000 switch_latencies=0 bundlesize=1 downlink_speeds=100000000000 oversub=1 radix_down=16 queue_down=150000 radix_up=16 queue_up=150000 tier=1 link_latency=1000000 switch_latencies=0 bundlesize=1 downlink_speeds=100000000000 oversub=1 radix_down=8 queue_down=150000 radix_up=0 queue_up=150000
queue_id 2 ecn_low 37500 ecn_high 145500
actual nodes 128
Creating 1 DCQCN flows and 1 TCP Cubic flows
pathcount 16
Setting flow size to 524289500
Created 1 DCQCN flows and 1 TCP Cubic flows
Both protocols share the SAME network queues - they will compete for bandwidth
Starting simulation
startflow dcqcn_64_0 at 0
Flow tcpsrc finished at 42.0896
Flow dcqcn_64_0 1590 finished at 86465.7 total bytes 349526
Trigger 0 fired, 1 targets
Done at 190000 us
CSV results written to htsim/sim/datacenter/results/review_ecn_off_interaction/dcqcn_vs_cubic_tcpEcnOff_500mb.csv

========================================
INTER-PROTOCOL FAIRNESS RESULTS
========================================

=== DCQCN Statistics ===
DCQCN flows completed: 1/1
DCQCN total bytes received: 524289000
DCQCN retransmits: 0
DCQCN per-flow throughput (Gbps): mean=48.5084 median=48.5084 p99=48.5084

=== TCP Cubic Statistics ===
TCP Cubic flows completed: 1/1
TCP Cubic total bytes received: 524290501
TCP Cubic retransmits: 6
TCP Cubic per-flow throughput (Gbps): mean=99.6523 median=99.6523 p99=99.6523

=== Competitive Fairness Analysis ===
Mode: PHASE ANALYSIS (at least one flow completed)
Phase 1 (overlap): 0 - 42089.6 us (42089.6 us)
Phase 2 (solo):    42089.6 - 86465.7 us (44376.1 us)
Cubic finished first. DCQCN ran solo for 44376.1 us
Estimated DCQCN solo bytes (Phase 2): 269076763

Competitive throughput (Phase 1 only):
  DCQCN: 255212237 bytes, 48.5084 Gbps
  Cubic: 524290501 bytes, 99.6523 Gbps

Competitive bandwidth share:
  DCQCN: 32.7404%
  Cubic: 67.2596%
Competitive JFI: 0.893529

=== Raw Bandwidth Share (total bytes, for reference) ===
DCQCN: 49.9999%
Cubic: 50.0001%

=== Jain's Fairness Index (per-flow) ===
Jain's Fairness Index (all flows): 0.893529

=== DCQCN Protocol Details ===
  rocesrc 0 CNPs=358 new_pkts=0 rtx_pkts=0
